{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import detect_face\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class['deemarc', 'unknown']\n",
      "Number of classes: 2\n",
      "Number of images: 50\n",
      "Loading feature extraction model\n",
      "Model filename: ./modelSaved/20170511-185253/20170511-185253.pb\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        datadir = './aligned/'\n",
    "        dataset = facenet.get_dataset(datadir)\n",
    "        paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "        print('Number of classes: %d' % len(dataset))\n",
    "        print('Number of images: %d' % len(paths))\n",
    "\n",
    "        print('Loading feature extraction model')\n",
    "        modeldir = './modelSaved/20170511-185253/20170511-185253.pb'\n",
    "        facenet.load_model(modeldir)\n",
    "\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128)\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'input:0' shape=<unknown> dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.get_shape())\n",
    "print(images_placeholder.get_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features for images\n",
      "number of image per epoch 1\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass to calculate embeddings\n",
    "print('Calculating features for images')\n",
    "batch_size = 1000\n",
    "image_size = 160\n",
    "nrof_images = len(paths)\n",
    "nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "emb_array = np.zeros((nrof_images, embedding_size))\n",
    "temStr = 'number of image per epoch ' + str(nrof_batches_per_epoch)\n",
    "print(temStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "1000\n",
      "50\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nrof_images)\n",
    "start_index = 1 * batch_size\n",
    "print(start_index)\n",
    "end_index = min((1 + 1) * batch_size, nrof_images)\n",
    "print(end_index)\n",
    "paths_batch = paths[start_index:end_index]\n",
    "print(paths_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_index: 0\n",
      "end_index: 50\n"
     ]
    }
   ],
   "source": [
    "emb_array = np.zeros((nrof_images, embedding_size))\n",
    "for i in range(nrof_batches_per_epoch):\n",
    "    start_index = i * batch_size\n",
    "    print('start_index: ' + str (start_index)) \n",
    "    end_index = min((i + 1) * batch_size, nrof_images)\n",
    "    print('end_index: ' + str (end_index)) \n",
    "    paths_batch = paths[start_index:end_index]\n",
    "    images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "    feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "    emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01490071  0.03965852 -0.02916748 ...,  0.04769536  0.03011187\n",
      "   0.13832133]\n",
      " [-0.03563273  0.05278063 -0.04849524 ..., -0.09301965 -0.01848567\n",
      "   0.00091949]\n",
      " [ 0.00065643  0.00284608 -0.08650736 ...,  0.05988909  0.04742663\n",
      "   0.06801361]\n",
      " ..., \n",
      " [ 0.01656157  0.01339139  0.0325558  ...,  0.05930727  0.03481149  0.09068   ]\n",
      " [-0.12511477 -0.04967868 -0.02054418 ...,  0.0076438  -0.04555624\n",
      "   0.08097502]\n",
      " [ 0.10240729 -0.06520001 -0.14631735 ...,  0.07053272 -0.0563504\n",
      "  -0.00889783]]\n"
     ]
    }
   ],
   "source": [
    "print(emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01490071  0.03965852 -0.02916748 -0.07327384  0.03740805 -0.12118302\n",
      "  0.01806211 -0.19123268 -0.09963465  0.01315908  0.06709067  0.08580038\n",
      " -0.05757007  0.02856414 -0.04124936  0.0325281  -0.12710212 -0.04057883\n",
      "  0.07477987 -0.0648637  -0.19588596  0.08105141  0.01804628 -0.00426263\n",
      " -0.03238119 -0.1068694  -0.13389543  0.09163025  0.01435086  0.0420995\n",
      " -0.09084287 -0.03761289 -0.06202683 -0.07141073 -0.01976791 -0.14572039\n",
      "  0.02195624 -0.01534773  0.02358442  0.0792337   0.16750066 -0.03042983\n",
      "  0.0313882  -0.07581261  0.04505441 -0.0166865  -0.00464379  0.05038027\n",
      "  0.01745155  0.07473124 -0.04480956 -0.0433794  -0.04011886  0.01781305\n",
      " -0.13802072 -0.09721706 -0.01702882 -0.06366867 -0.07362789 -0.01402358\n",
      " -0.08387844  0.0656831   0.03144043 -0.02313725  0.02673012 -0.05280549\n",
      "  0.0748082   0.01934608 -0.0516469   0.012383   -0.22707348 -0.07394178\n",
      "  0.08447153  0.14238741  0.11705635 -0.0049876  -0.05457335 -0.09084585\n",
      "  0.0566313  -0.1299372  -0.12606598  0.02478188 -0.0187568  -0.00093571\n",
      " -0.03378204  0.14148049  0.1746802  -0.08320967  0.02618389  0.00167892\n",
      " -0.00281139  0.03940126  0.00568746 -0.14886579 -0.08691324  0.05181787\n",
      "  0.04064493 -0.00852921 -0.00093711  0.05613552  0.07084182  0.02039049\n",
      "  0.0126958  -0.06185981  0.13025773 -0.14279713 -0.30320126 -0.07358862\n",
      " -0.08310217 -0.01533795 -0.24653311 -0.03937052  0.07138214 -0.01065034\n",
      " -0.0549463  -0.10373877  0.11874285  0.23801461 -0.0977432   0.10612917\n",
      " -0.06664183  0.07182104 -0.07285506 -0.09467045  0.13395943  0.04769536\n",
      "  0.03011187  0.13832133]\n"
     ]
    }
   ],
   "source": [
    "print(emb_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier  \n",
    "def knn_classifier(train_x, train_y):  \n",
    "    from sklearn.neighbors import KNeighborsClassifier  \n",
    "    model = KNeighborsClassifier(n_neighbors=3)  \n",
    "    model.fit(train_x, train_y)  \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def gaussianNB_classifier(train_x, train_y): \n",
    "    model = GaussianNB()\n",
    "    model.fit(train_x, train_y)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def svc_classifier(train_x, train_y): \n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(train_x, train_y)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eucliDist_clssifier():\n",
    "    def __init__(self,track):\n",
    "        self.target = track\n",
    "        \n",
    "    def distance(self, v1, v2):\n",
    "        return np.sqrt(np.sum((v1 - v2) ** 2))   \n",
    "    \n",
    "    def predict(self,Persons):\n",
    "        matched = []\n",
    "        for curPer in Persons:\n",
    "            dist = self.distance(self.target,curPer)\n",
    "            print(dist)\n",
    "            if dist > 1:\n",
    "                matched.append(1)\n",
    "            else:\n",
    "                matched.append(0)\n",
    "#                 print('matched')\n",
    "        \n",
    "        return matched\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "0.0\n",
      "0.893975289497\n",
      "0.639209917284\n",
      "0.856836591821\n",
      "0.803008827245\n",
      "0.713504419447\n",
      "0.738244478486\n",
      "1.20447515905\n",
      "0.886609528465\n",
      "1.15744942522\n",
      "0.664108734812\n",
      "0.65334866366\n",
      "0.771409151189\n",
      "0.721613037629\n",
      "0.693516848423\n",
      "0.764705454229\n",
      "0.72247081489\n",
      "0.723692799107\n",
      "0.757012508455\n",
      "0.8283088661\n",
      "0.905530889778\n",
      "0.954708491738\n",
      "0.769823333134\n",
      "0.66577300779\n",
      "0.744211226317\n",
      "0.823391849894\n",
      "1.01094820464\n",
      "0.927382096494\n",
      "0.791898857214\n",
      "1.08941943974\n",
      "1.27077548709\n",
      "1.2662202292\n",
      "1.33741188193\n",
      "1.38516535285\n",
      "1.23937142043\n",
      "1.31179414292\n",
      "1.41189175579\n",
      "1.35118569113\n",
      "1.08630635925\n",
      "0.99767290034\n",
      "1.12554251262\n",
      "1.46072342688\n",
      "1.42572335476\n",
      "1.18859693068\n",
      "1.18211845562\n",
      "1.49811774429\n",
      "1.10265227733\n",
      "1.26200548789\n",
      "1.34976038231\n",
      "1.38637353497\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "accuracy: 92.00%\n",
      "Saved classifier model to file \"./class/my_classifier.pkl\"\n",
      "Goodluck\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "\n",
    "classifier_filename = './class/my_classifier.pkl'\n",
    "classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "\n",
    "# Train classifier\n",
    "print('Training classifier')\n",
    "# model = SVC(kernel='linear', probability=True)\n",
    "# classifiers = svc_classifier \n",
    "model = eucliDist_clssifier(emb_array[0])\n",
    "# model = classifiers(emb_array,labels) \n",
    "predict = model.predict(emb_array) \n",
    "print(predict)\n",
    "# model.fit(emb_array, labels)\n",
    "accuracy = metrics.accuracy_score(labels, predict)  \n",
    "print ('accuracy: %.2f%%' % (100 * accuracy)  ) \n",
    "# # Create a list of class names\n",
    "class_names = [cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "# # Saving classifier model\n",
    "with open(classifier_filename_exp, 'wb') as outfile:\n",
    "    pickle.dump((model, class_names), outfile)\n",
    "print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "print('Goodluck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_proba(emb_array) \n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distance(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sucpect = emb_array[0]\n",
    "ret = distance(sucpect,emb_array)\n",
    "predict = []\n",
    "for person in emb_array:\n",
    "    dist = distance(person,sucpect)\n",
    "    print(dist)\n",
    "    if dist > 1:\n",
    "        predict.append(1)\n",
    "    else:\n",
    "        predict.append(0)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(labels, predict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
